---
title: "**Refined moderation Analysis with binary outcomes using Modana**"
author: "Eric Anto"
date: "`r format(Sys.time(), '%A, %B %d, %Y')`"
format: gfm
#bibliography: reference.bib
output: rmarkdown::html_vignette
urlcolor: blue
vignette: >
  %\VignetteIndexEntry{Modana}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
 options(rmarkdown.html_vignette.check_title = FALSE)
```

## Introduction
Moderation analysis for evaluating differential treatment effects serves as the bedrock of precision medicine, which is of growing interest in many fields. In the analysis of data with binary outcomes, we observe an interesting symmetry property concerning the ratio of odds ratios, which suggests that heterogeneous treatment effects could be equivalently estimated via a role exchange between the outcome and treatment variable in logistic regression models. We then obtain refined inference on moderating effects by rearranging data and combining two models into one via a generalized estimating equation approach. The improved efficiency is helpful in addressing the lack-of-power problem that is common in the search for important moderators. We investigate the proposed method by simulation and provide an illustration with data from a randomized trial on wart treatment.

## Getting Started

This `Modana` package implements a refinement of moderation analysis with binary outcomes, as proposed by [Anto and Su (2023)](https://doi.org/10.1177/09622802231151206). The function fits three models of interest: a direct model, an inverse model, and a generalized estimating equation (GEE) model. The direct and inverse models are fitted using the `glm` function to verify the symmetry property of odds ratio/relative risk in moderation analysis for the main treatment effect as well as the moderating effects. The GEE model is fitted using the `geeglm` function and is used to estimate the treatment effect accounting for within-cluster correlation. The `Modana` package has three different built functions.


## Installing and using the package
The package is in development stage and only available on github link [github](https://github.com/Quamena/Modana).
You can install the `Modana` package and use it for your moderation analysis.
```{r,  eval = FALSE, message = FALSE, warning=FALSE}
devtools::install_github("Quamena/Modana")
```

```{r, warning=FALSE, echo=FALSE, message=FALSE}
install.packages("~/Modana_0.1.0.tar.gz", repos = NULL)
```

```{r, warning = FALSE, eval=FALSE}
library(Modana)
```

```{r warning = FALSE, echo = FALSE}
library(Modana)
```

## Simulating data
The function `sim_data()` generates simulated data for a randomized controlled trial or an observational study
The function takes several arguments including a formula object, data frame, the name of the binary response and binary treatment column in the data, a vector of potential effect modifiers, and other arguments that are passed to the geeglm function. If effect modifiers are specified, the function fits models with interaction terms between the effect modifiers and the treatment variable.

### Function Arguments 
```{r, eval = FALSE}
sim_data(n = 100, b0, a0 = NULL, link.function = "logistic",
                     sigma=1, uniform=TRUE, c0 = 1, binary.Xs=FALSE,
                     rho = 0.2, observational = FALSE, trt.p = 0.5,
                     interaction = NULL, details = FALSE)
```


- `n`	the number of observations to generate.

- `b0`	a vector of coefficients for the linear predictor in the outcome model. The length of `b0` should be equal to the number of covariates plus one (for the intercept term). The first element of `b0` corresponds to the intercept, and the remaining elements correspond to the coefficients for the covariates which may include include interaction coefficients.

- `a0` 	a vector of coefficients for the linear predictor in the treatment assignment model. The length of `a0` should be equal to the number of covariates plus one (for the intercept term). The first element of `a0` corresponds to the intercept, and the remaining elements correspond to the coefficients for the covariates. This argument is only used if 'observational = TRUE'.

- `link.function`	a character string specifying the link function to use in the outcome model. The default is 'logistic', which corresponds to the logistic link function. The other option is 'exp', which corresponds to the log-linear link function.

- `sigma` 	the standard deviation of the covariate distribution. The default value is '1'.

- `uniform`	a logical value indicating whether to transform the covariates to a uniform distribution on the interval '[0, c0]'. The default value is 'FALSE'.

- `c0`	the upper limit of the uniform distribution used to transform the covariates. The default value is 1.

- `binary.Xs`	a logical value indicating whether to change some columns of continuous covariates into binary variables. The default value is 'FALSE'.

- `rho`	the correlation parameter used to generate the covariance matrix. The default value is '0.2'.

- `observational`	 a logical value indicating whether to generate data for an observational study. The default value is FALSE.

- `trt.p`	 the probability of receiving the treatment. This argument is only used if 'observational = FALSE'. The default value is 0.5.

- `interaction`	a vector of indices indicating which covariates should be used to create interaction terms with the treatment variable. The length of interaction should be less than or equal to the number of covariates. The default value is 'NULL', which indicates no interaction terms should be used.

- `details`	a logical value indicating whether to print details about the generated data. The default value is FALSE.


### summary.refinedmod
`summary.refinedmod` is applicable to an argument of class `refinedmod`. This produces a table summary associated with the respective models which includes `estimated coefficients`, `standard errors`, and `p-values`.

##### Usage
```{r codeChunk4, eval=FALSE}
summary.refinedmod(object, model = NULL, ...)
```

### Arguments
- `object` an object of class `refinedmod`
- `model` argument to specify which model to call. The is default, `NULL` which will produce a summary result for the `gee refined model`. When model is set `1`, a summary for the `direct model` is reported, `2` will report summary for the `inverse model` while all other values will produce a summary for all the models.
- `...` not in use currently

### plot.refinedmod
`plot.refinedmod` is applicable to an argument of class `refinedmod`. This will produce an $1\times 3$ panel plots residuals and predicted values for the three models.

### Usage
```{r codeChunk5, eval=FALSE}
plot.refinedmod(x, ...)
```

### Arguments
- `x` an object of class `refinedmod`
- `...` not in use currently

### print.refinedmod
`print.refinedmod` is applicable to an argument of class `refinedmod`. This prints results of the refined moderation analysis.

### Usage
```{r codeChunk3, eval=FALSE}
print.refinedmod(x, ...)
```

### Arguments
- `x` an object of class `refinedmod`
- `...` not in use currently


### Example usage
```{r}
#require(MASS)
set.seed(1099)
b0 <- c(1, 1.2, 1, 1.5, -2, -.5, 1.2, 1.5)
a0 <- c(-1, 1.5, -1, 1.5)
#a0 <- c(-2, 2, 2, 0, 1)
b0 <- c(-1.5, 1.5, 1.5, -2, 2, -.5, -1, 1.5)
 datt <- sim_data(n = 100, b0, a0 = NULL, binary.Xs = FALSE,
                      sigma = 1, uniform = FALSE, c0 = 1,
                      link.function = "logistic", rho = 0.2,
                      observational = FALSE, trt.p = 0.5,
                      interaction = 1:2, details = FALSE)
head(datt)
#compares.plot <- function() 
```

## Building a data structure that mimicks a clustered/longitudinal data 

The main idea of this computing trick is to rearrange the data into a format that mimics a clustered or longitudinal data. This is done by using the `swaparr()` function which performs a role exchange of the response variable and treatment variable columns in the original data and then stacking the resultant data on top of the original data. The function then introduces a dummy variable to distinguish between the direct and inverse models alongside with a cluster `id`. The `swaparr()` function only takes three arguments.

### Function Arguments
```{r, eval=FALSE}
swaparr(data, y = "y", trt = "trt")
```

- `data` original data frame containing the variables in the model.
- `y` name of a binary response column in data.
- `trt`	name of a binary treatment column in data.

### Example usage
```{r}
swaparr(data = datt, y = "y", trt = "trt") |> head()
```

## Estimating main treatment and heterogeneous treatment effects

The `refinedmod()` function implements refined moderation analysis to estimate both treatment effect and moderating effects associated with two logistic regression models with binary outcomes/treatment via generalized estimating equations (GEE). 
The function first performs a role swap algorithm on the original data to obtain a clustered data of size `2` (i.e., swapping the roles of the response variable and treatment variable columns in the original data data and then stacking the resultant data on top of the original data). A dummy variable z is introduced to distinguish the two glm models. Three models of interest are fitted using `refinedmod()`, i.e., two glms (for the direct and inverse models) and a combined GEE model. The function has several arguments. It provides the option to include interaction effects between the moderators and the treatment. The function takes a formula, the name of the binary response variable, the name of the binary treatment variable, and the names of the potential effect modifiers as inputs. It returns the estimated coefficients, standard errors, p-values, and confidence intervals for the main treatment effect and moderating effects. The function also provides the option to print summary results for the three models.

### Function Arguments
```{r, eval = FALSE}
refinedmod(formula, y = "y", trt = "trt",
            effmod = NULL, data, detail = FALSE, ...)
```


- `formula`	an object of class "formula" (or one that can be coerced to that class): a symbolic description of the model to be fitted.
- `data` original data frame containing the variables in the model.
- `y` name of a binary response column in data.
- `trt`	name of a binary treatment column in data.
- `effmod`	a vector of potential effect modifiers used in the data.
- `detail`	a logical argument specified to print summary results of the direct and inverse models.
If the `detail` argument is set to TRUE, the function will print summary results of the direct and inverse models. The function returns an object of type `glm` and `geeglm`, and can be used to extract summary information using the summary function.

## Confidence Interval for model parameters

`confint` Computes confidence intervals for one or more parameters in a fitted model of class `refinedmod`.

### Function Arguments
```{r, eval=FALSE}
confint(object, parm, model = 1, level = 90, ...)
```

`object`	a fitted model object of class `refinedmod`.

`parm`	a specification of which parameters are to be given confidence intervals, either a vector of numbers or a vector of names. If missing, all parameters are considered.

`level`	the confidence level required.
`model` the model specified to compute confidence interval for. If `model` = 1, the direct model confidence will be computed, `model` = 2, the inverse model confidence interval will be computed, otherwise the the gee model confidence interval will be computed.


`...`	additional argument(s) for methods.

### Example usage on a simulated data
```{r}
getres <- refinedmod(formula = y ~ trt + x1 + x2 + x3 + x4,
                     detail = FALSE, y = "y",
                    trt = "trt", data = datt,
                     effmod = c("x1", "x2"),
                      corstr = "independence")
print(getres, model = 2)
```

The refined estimates of the main treatment and effect modifiers can pulled and compared with both the direct and indirect models.
```{r}
#print(getres)
summary(getres)
```


### Example usage on a real-world data
```{r}
data(Warts, package =  "Modana")
dat <- Warts
#data wrangling
dat$type <- ifelse(dat$type == 3, 1, 0)
```


```{r}
res <- refinedmod(formula = response ~ cryo + age + time + type,
                     detail = FALSE, y = "response",
                    trt = "cryo", data = dat,
                     effmod = c("age", "type"),
                      corstr = "independence")

summary(res)
```

```{r}
plot(res)
```

```{r}
confint(res, model = 3)
```



## Performing simulation studies using the Modana package


Moderation analysis essentially involves treatment-by-covariates interactions.

- We employ the nice symmetry property about ratio of odds ratios, which suggests that heterogeneous treatment effects could be equivalently estimated via a role exchange between the outcome and treatment variable in logistic regression models. 


- Refined inference on moderating effects can be obtained by rearranging data and combining two models into one via a GEE (generalized estimating equation) approach. 


- This approach can be helpful in identifying treatment-by-covariate interactions (a common problem in the search for important moderators). 



- We use the `Modana` package to carry out simulation.


## The set-up

- Suppose that the available data, $\mathcal{D} = \left\{(y_i,t_i, x_i): i=1, \ldots, n \right\}$, consist of $n$ IID copies of $(y, t, x)$, where both $y$ and $t$ are 0/1-coded binary variables and $X \in \mathbb{R}^p$ is a $p$-dimensional covariate vector.

- A $y$ value of 1 indicates the occurrence of an event of interest (e.g., death) and a $y$ value of 0 indicates the absence of the event (e.g., survival). 

-  A treatment assignment variable $t$ has value 1 for participants who are randomized into the treated group and value 0 for the untreated.

- With the covariate vector fixed at $\bf{x}=\bf{a},$. The ratio of the odds in the treated group and the odds in the untreated group is defined as.
\begin{equation}
\label{OR-Y}
OR^{(y)}_{\textbf{a}} =  \frac{\Pr(y=1\, |\, t=1, \textbf{x}=\textbf{a}) / \Pr(y=0\, |\, t=1, \textbf{x}=\textbf{a})}{ \Pr(y=1\, |\, t=0, \textbf{x}=\textbf{a}) / \Pr(y=0\, |\, t=0, \textbf{x}=\textbf{a})}
\end{equation}


- Ratio of Odds Ratios (ROR)
  - In moderation analysis, one is primarily concerned about differential treatment           effects among patients with heterogeneous characteristics.
  - Consider two sets of patients or individuals: one with covariates $\bf{x}= \bf{a}$ and     the other with covariates $\bf{x} = \bf{b}$



## The set-up (Cont'd)

- Ratio of Odds Ratios (ROR)
 - By definition, ROR compares the treatment efficacy (measured by OR) between the two       patient sets, as given by $ROR^{(y)}(\textbf{a}:\textbf{b}) = OR^{(y)}_{\textbf{a}}/ OR^{(y)}_{\textbf{b}}.$
 - If we swap the roles of $y$ and $t$, both OR and ROR remain the same. 
 - Specifically, let $OR^{(t)}_{\textbf{a}}$ denote the odds ratios of being treated for     comparing cases ($y=1$) versus controls ($y=0$), while fixing $\textbf{x}=\textbf{a}$, as
 
\begin{equation}
\label{OR-T}
OR^{(t)}_{\textbf{a}} =  \frac{\Pr(t=1\, |\, y=1, \textbf{x}=\textbf{a}) / \Pr(t=0\, |\, y=1, \textbf{x}=\textbf{a})}{\Pr(t=1\, |\, y=0, \textbf{x}=\textbf{a}) / \Pr(t=0\, |\, y=0, \textbf{x}=\textbf{a})}.
\end{equation}

- Define $ROR^{(t)}(\textbf{a}:\textbf{b}) = OR^{(t)}_{\textbf{a}} / OR^{(t)}_{\textbf{b}}$ to be the ROR compares the OR of being treated between the two patients sets.



## The set-up (Cont'd)


The proposition:



Let $OR^{(y)}_{\textbf{a}},$ $OR^{(t)}_{\textbf{a}}$, $ROR^{(y)}(\textbf{a}:\textbf{b})$ and $ROR^{(t)}(\textbf{a}:\textbf{b})$ be the odds ratios and the ratios of odds ratios as defined above. We have 


(i)  $OR^{(y)}_{\textbf{a}} = OR^{(t)}_{\textbf{a}},~ \forall \, \textbf{a}.$ 
(ii) $ROR^{(y)}(\textbf{a}:\textbf{b}) = ROR^{(t)}(\textbf{a}:\textbf{b}),~ \forall \, \textbf{a}, \textbf{b}.$



## Implications on Logistic Regression Models


Suppose that one is interested in the main effect of treatment $t$ and fits the following two logistic modes by swapping the roles of $y$ and $t$

\begin{equation}
\left\{
\begin{array}{lcl}
\mbox{logit} \Pr(y=1 \, | \, t, \textbf{x}) &=&  \beta_0 + \beta_1 t + \textbf{x}^T\bf{\beta}_2 + t \cdot \text{x}^T \bf{\gamma}  \\
\mbox{logit} \Pr(t=1 \, | \, y, \textbf{x}) &=&  \beta'_0 + \beta'_1 y + \bf{x}^T \bf{\beta}'_2 + y \cdot \textbf{x}^T \bf{\gamma}'
\end{array}
\right.
\label{model-main}
\end{equation}

- Our proposition `(i)` implies that  $\beta_1 = \beta'_1,$ since $\exp(\beta_1) = OR^{(y)}_{\textbf{a}}$ and $\exp(\beta'_1) = OR^{(t)}_{\textbf{a}}$ with any fixed $\textbf{x} = \textbf{a}.$

- By Proposition (ii), $\exp(\gamma_j) = ROR^{(y)}(\textbf{a}: \textbf{b})$ and $\exp(\gamma'_j) = ROR^{(t)}(\textbf{a}: \textbf{b}).$. Thus, $\gamma_j = \gamma'_j$ and hence $\bf{\gamma} =\bf{\gamma}'.$



## Refined Estimation of Moderating Effects

We can be further the above models reduced to 

\begin{equation}
\left\{
\begin{array}{lcl}
\mbox{logit} \Pr(y=1 \, | \, t, \textbf{x}) &=&  \beta_0 + \beta_1 t + \textbf{x}^T\bf{\beta}_2 + t \cdot \text{x}^T \bf{\gamma}  \\
\mbox{logit} \Pr(t=1 \, | \, y, \textbf{x}) &=&  \beta'_0 + \beta_1 y + \bf{x}^T \bf{\beta}'_2 + y \cdot \textbf{x}^T \bf{\gamma}
\end{array}
\right.
\label{model-main1}
\end{equation}


- To come up with a better estimator of $\bf{\gamma}$ in moderation analysis, 
  - we estimate the parameters by pooling together the likelihood or quasi-likelihood functions of the two models as if they were built on independent data. 
  - The main idea of this computing trick is to rearrange data
into a format for clustered or longitudinal data

  - Define $y'_{ij} = y_i$  if $j=1$ and  $y'_{ij} = t_i$ if $j=2$; define 
$t'_{ij} = t_i$ if $j=1$ and $t'_{ij} = y_i$ if $j=2$; let $z_{ij} =j-1$ and $\textbf{x}_{ij}=\textbf{x}_i$ for $j=1, 2$ and $i=1, \ldots , n.$  
  - We arrive at a clustered data set $\mathcal{D}'=\{(y'_{ij}, t'_{ij}, z_{ij}, \textbf{x}_{ij}): i=1, \ldots, n \,\,\text{and} \,\, j=1, 2\}$, which is obtained by swapping the response and treatment columns in the original data $\mathcal{D}$ and then stacking it on top of $\mathcal{D}$. 
  - The dummy variable $z$ is introduced to distinguish the two models. 
  


## Refined Estimation of Moderating Effects (cont'd)


Consider the following marginal model for $y'_{ij}$



\begin{eqnarray}
\label{model-marginal}
\log \frac{\pi_{ij}}{1- \pi_{ij}} & = & \theta_0 + \theta_1 z_{ij} + 
\theta_2 t'_{ij} + \bf{\theta}_3^T \textbf{x}_{ij} + z_{ij} \cdot \bf{\theta}_4^T \textbf{x}_{ij} + t'_{ij}\cdot \bf{\theta}_5^T \textbf{x}_{ij},
\end{eqnarray}

where $\pi_{ij} = E(y'_{ij} \,|\, t'_{ij}, z_{ij}, \textbf{x}_{ij}) = \Pr(y'_{ij}=1\,|\, t'_{ij}, z_{ij}, \textbf{x}_{ij})$. 

- Introduce $\textbf{x}'_{ij}=(1, z_{ij}, t'_{ij}, \textbf{x}_i, z_{ij} \textbf{x}_i^T, t'_{ij} \textbf{x}_i^T)^T$ to rewrite the above model as $\pi_{ij} = \pi( \bf{\theta}^T \textbf{x}'_{ij})$, where the expit or logistic function $\pi(x) = \exp(x) / \{ 1 + \exp(x)\}$ is the inverse function of the logit function.



- By reparameterization of the above model: 
  - $\theta_0 = \beta_0$, $\theta_1 = \beta'_0- \beta_0$, $\theta_2 = \beta_1$,               $\bf{\theta}_3 = \bf{\beta}_2$,  $\bf{\theta}_4 = \bf{\beta}'_2 - \bf{\beta}_2$
  - Importantly, $\bf{\theta}_5 = \bf{\gamma}.$ 
  - Parameters $\bf{\theta} = (\theta_0, \theta_1, \ldots, \bf{\theta}_5^T)^T$ in the marginal model above can be conveniently estimated with the GEE approach. 




## Numerical Results


- Data are generated from the model

\begin{equation}
\label{model-simulation}
\log \frac{\Pr(y_i=1 \, | \, t_i, \textbf{x}_i)}{\Pr(y_i=0 \, | \, t_i, \textbf{x}_i)} = 
\beta_0 + \beta_1 t_i + \bf{x}_i^T \bf{\beta}_2 + t_i \cdot \textbf{x}_i^T \bf{\gamma}, 
\end{equation}



- Main Effect Estimation (Based on Proposition `(i)`):

  - We set $\bf{\gamma} = \bf{0}$ so that the model is additive; in addition, $\beta_0= -1$, $\beta_1 = 0.5,$ $\bf{\beta}_2 = (0.5, -1, 1)^T.$ We are interested in estimating $\beta_1$.



- Moderating Effect Estimation (Based on Proposition `(ii)`):
\begin{eqnarray}
\log \frac{\Pr(y=1 \, | \, t, \textbf{x})}{\Pr(y=0 \, | \, t, \textbf{x})} = -1 + 0.5 \, t + 0.5 \, x_1 - \frac{b}{2} x_2 +  x_3 + btx_1, 
\label{model-studyII}
\end{eqnarray}
  - where $x_1$ is the only effect-moderator of the treatment with slope $\gamma =b$ is of interest. The value of $b$ varies  from no to weak and strong moderating effects (e.g., $\{0.0, 0.5, 1.0, \ldots, 5\}$). 


## Simulation Results



```{r}
library(ggplot2)
library(dplyr)
# fn <- system.file(file.path("~/Modana/inst",
#   "array.slurm", "modana.slurm.R"),
#   package = "Modana"
#   )
maineff <- readRDS("~/Modana/inst/maineff.rds")
func <- \(x) as.numeric(as.character(x))
plotdata <- maineff %>% dplyr::mutate_at(c("lwr", "upr"), func) %>% 
  tibble::remove_rownames() %>% as.data.frame()

#Plot of main effect
plotdata %>% filter(Est %in% c("y", "trt"), 
              corcoef == .5, N %in% c(100, 500),
              vartype %in% "continuous") %>% 
  group_by(method) %>%
  ggplot(aes(Estimate)) +
  geom_density(col = "red", fill = "cadetblue") +
 # facet_grid(rows = vars(method), scales = "free") +
  facet_wrap(vars(N, method))

```


```{r}
#Summary table for Main effect
summtab <- plotdata %>% 
  filter(Est %in% c("trt", "y"), corcoef == .5,
         N %in% c(100, 500),
         vartype %in% "continuous") %>% 
  group_by(method, N) %>% 
  summarise(Means = mean(Estimate), SD = sd(Estimate),
            "Average SE" = mean(`Std. Error`))
knitr::kable(summtab)

```




## Simulation Results (cont'd)


```{r}
#| fig-cap: Empirical densities from simulation results for assessing the moderating effect  
#| warning: false

effmod <- readRDS("~/Modana/inst/effmod.rds")
func <- \(x) as.numeric(as.character(x))
plotdata <- effmod %>% dplyr::mutate_at(c("lwr", "upr"), func) %>% 
  tibble::remove_rownames() %>% as.data.frame()

#Plot of moderating effect
plotdata %>% filter(Est %in% c("y:x1", "trt:x1"), 
                    corcoef == .5, N %in% c(100, 500),
                    vartype %in% "continuous") %>% 
  #group_by(method) %>%
  ggplot(aes(Estimate)) +
  geom_density(col = "red", fill = "cadetblue") +
  # facet_grid(rows = vars(method), scales = "free") +
  facet_wrap(vars(N, method))

```


```{r}

#Summary table for Moderating effect
sumtab <- plotdata %>% dplyr::mutate_at(c("lwr", "upr"), func) %>% 
  tibble::remove_rownames() %>% as.data.frame() %>%
  mutate(Z = pchisq((Estimate/`Std. Error`)^2, df = 1, lower.tail=FALSE),
         Pind = ifelse(Z <= 0.05, 1, 0)) %>%
filter(Est %in% c("y:x1", "trt:x1"), corcoef == .5,
       N %in% c(100, 1000),
       vartype %in% "continuous") %>%
  group_by(method, N) %>% summarise(
    Means = mean(Estimate), SD = sd(Estimate),
    "Average SE" = mean(`Std. Error`),
   # POWER = mean(Pind),
  lower = Means-qnorm((1+.95)/2)*`Average SE`,
  upper = Means+qnorm((1+.95)/2)*`Average SE`,
  conf_width = upper - lower)
knitr::kable(sumtab)
```


## Results

```{r}
#| fig-cap: Empirical confidence interval from simulation results for assessing the moderating effect 
plotdata %>% filter(Est %in% c("y:x1", "trt:x1"), corcoef == .5,
                    N %in% c(100, 500),
                    vartype %in% "continuous") %>%
  #group_by(method) %>%
ggplot(aes(Estimate)) +        # ggplot2 plot with confidence intervals
  #geom_point() +
  geom_errorbar(aes(ymin = lwr, ymax = upr, col = "cadetblue")) +
  facet_wrap(vars(N, method))

```

